"""
TEXT ANALYZER
- Grammar correctness rating (0-100)
- Sentiment detection (Positive/Negative)
- Sentiment strength rating (0-100)

Installation:
pip install language-tool-python textblob
"""

import language_tool_python
from textblob import TextBlob
from typing import Dict, Tuple


class TextAnalyzer:
    """Analyze text for grammar and sentiment"""
    
    def __init__(self):
        print("ðŸ”§ Initializing Text Analyzer...")
        print("   Loading grammar checker...")
        self.grammar_tool = language_tool_python.LanguageTool('en-US')
        print("âœ… Text Analyzer ready!\n")
    
    def analyze_grammar(self, text: str) -> Tuple[float, int, list]:
        """
        Analyze grammatical correctness
        Returns: (score out of 100, error count, list of errors)
        """
        if not text.strip():
            return 0.0, 0, ["Empty text provided"]
        
        # Check for grammar errors
        matches = self.grammar_tool.check(text)
        error_count = len(matches)
        
        # Calculate score based on text length and errors
        word_count = len(text.split())
        
        if word_count == 0:
            return 0.0, 0, ["No words found"]
        
        # Score calculation: penalize based on error rate
        error_rate = error_count / word_count
        
        # More forgiving scoring system
        if error_rate == 0:
            score = 100.0
        elif error_rate < 0.02:  # Less than 2% error rate
            score = 95.0
        elif error_rate < 0.05:  # Less than 5% error rate
            score = 85.0
        elif error_rate < 0.10:  # Less than 10% error rate
            score = 70.0
        elif error_rate < 0.15:
            score = 55.0
        elif error_rate < 0.20:
            score = 40.0
        else:
            score = max(20.0, 100 - (error_rate * 200))
        
        # Extract error details
        error_details = []
        for match in matches[:10]:  # Limit to first 10 errors
            error_details.append({
                'message': match.message,
                'context': match.context,
                'suggestions': match.replacements[:3]  # Top 3 suggestions
            })
        
        return score, error_count, error_details
    
    def analyze_sentiment(self, text: str) -> Tuple[str, float, float]:
        """
        Analyze sentiment
        Returns: (sentiment label, sentiment score 0-100, polarity -1 to 1)
        """
        if not text.strip():
            return "Neutral", 50.0, 0.0
        
        # Get sentiment using TextBlob
        blob = TextBlob(text)
        polarity = blob.sentiment.polarity  # Range: -1 (negative) to 1 (positive)
        subjectivity = blob.sentiment.subjectivity  # Range: 0 (objective) to 1 (subjective)
        
        # Determine sentiment label
        if polarity > 0.1:
            sentiment_label = "Positive"
        elif polarity < -0.1:
            sentiment_label = "Negative"
        else:
            sentiment_label = "Neutral"
        
        # Convert polarity to 0-100 scale
        # Scale: -1 to 1 becomes 0 to 100
        sentiment_score = ((polarity + 1) / 2) * 100
        
        # Adjust score based on strength
        # If sentiment is strong (far from neutral), increase the score difference from 50
        strength = abs(polarity)
        if strength > 0.5:  # Strong sentiment
            if polarity > 0:
                sentiment_score = min(sentiment_score * 1.1, 100)
            else:
                sentiment_score = max(sentiment_score * 0.9, 0)
        
        return sentiment_label, sentiment_score, polarity
    
    def analyze(self, text: str) -> Dict:
        """
        Complete analysis of text
        Returns dictionary with all metrics
        """
        print(f"\n{'='*70}")
        print("ðŸ“ ANALYZING TEXT")
        print(f"{'='*70}\n")
        
        if not text.strip():
            return {
                'error': 'Empty text provided',
                'text': text
            }
        
        print(f"Text: \"{text[:100]}{'...' if len(text) > 100 else ''}\"\n")
        
        # Grammar analysis
        print("ðŸ” Checking grammar...")
        grammar_score, error_count, errors = self.analyze_grammar(text)
        
        # Sentiment analysis
        print("ðŸ’­ Analyzing sentiment...")
        sentiment_label, sentiment_score, polarity = self.analyze_sentiment(text)
        
        # Prepare results
        results = {
            'text': text,
            'word_count': len(text.split()),
            'character_count': len(text),
            
            # Grammar metrics
            'grammar_score': round(grammar_score, 2),
            'grammar_error_count': error_count,
            'grammar_errors': errors,
            'grammar_rating': self._get_rating(grammar_score),
            
            # Sentiment metrics
            'sentiment_label': sentiment_label,
            'sentiment_score': round(sentiment_score, 2),
            'sentiment_polarity': round(polarity, 3),
            'sentiment_rating': self._get_rating(sentiment_score),
        }
        
        # Print results
        print(f"\n{'='*70}")
        print("ðŸ“Š ANALYSIS RESULTS")
        print(f"{'='*70}\n")
        
        print("ðŸ“ GRAMMAR ANALYSIS:")
        print(f"   Score: {grammar_score:.2f}/100 ({results['grammar_rating']})")
        print(f"   Errors Found: {error_count}")
        
        if errors and error_count > 0:
            print(f"\n   Top Errors:")
            for i, error in enumerate(errors[:5], 1):
                print(f"   {i}. {error['message']}")
                if error['suggestions']:
                    print(f"      Suggestions: {', '.join(error['suggestions'])}")
        
        print(f"\nðŸ’­ SENTIMENT ANALYSIS:")
        print(f"   Sentiment: {sentiment_label}")
        print(f"   Score: {sentiment_score:.2f}/100 ({results['sentiment_rating']})")
        print(f"   Polarity: {polarity:.3f} (range: -1 to +1)")
        
        print(f"\n{'='*70}\n")
        
        return results
    
    def _get_rating(self, score: float) -> str:
        """Convert numeric score to rating label"""
        if score >= 90:
            return "Excellent"
        elif score >= 80:
            return "Very Good"
        elif score >= 70:
            return "Good"
        elif score >= 60:
            return "Fair"
        elif score >= 50:
            return "Average"
        else:
            return "Needs Improvement"
    
    def batch_analyze(self, texts: list) -> list:
        """Analyze multiple texts"""
        results = []
        
        print(f"\n{'='*70}")
        print(f"ðŸ“š BATCH ANALYSIS - {len(texts)} texts")
        print(f"{'='*70}")
        
        for i, text in enumerate(texts, 1):
            print(f"\n[{i}/{len(texts)}]")
            result = self.analyze(text)
            results.append(result)
        
        # Summary
        print(f"\n{'='*70}")
        print("ðŸ“Š BATCH SUMMARY")
        print(f"{'='*70}\n")
        
        avg_grammar = sum(r['grammar_score'] for r in results) / len(results)
        avg_sentiment = sum(r['sentiment_score'] for r in results) / len(results)
        
        positive_count = sum(1 for r in results if r['sentiment_label'] == 'Positive')
        negative_count = sum(1 for r in results if r['sentiment_label'] == 'Negative')
        neutral_count = sum(1 for r in results if r['sentiment_label'] == 'Neutral')
        
        print(f"Average Grammar Score: {avg_grammar:.2f}/100")
        print(f"Average Sentiment Score: {avg_sentiment:.2f}/100")
        print(f"\nSentiment Distribution:")
        print(f"   Positive: {positive_count} ({positive_count/len(results)*100:.1f}%)")
        print(f"   Negative: {negative_count} ({negative_count/len(results)*100:.1f}%)")
        print(f"   Neutral: {neutral_count} ({neutral_count/len(results)*100:.1f}%)")
        print()
        
        return results


# ============================================================================
# USAGE EXAMPLES
# ============================================================================

def main():
    """Example usage"""
    
    print("\n" + "ðŸŽ¯"*35)
    print("     TEXT ANALYZER")
    print("     Grammar & Sentiment Analysis")
    print("ðŸŽ¯"*35 + "\n")
    
    # Initialize analyzer
    analyzer = TextAnalyzer()
    
    # Example texts
    examples = [
        "This is an excellent product! I absolutely love it and highly recommend it to everyone.",
        "The service was terrible and the staff were rude. I will never come back here again.",
        "The weather is nice today.",
        "This are a bad sentence with many mistake in grammer and spelling.",
        "I can't believe how amazing this experience was! Everything exceeded my expectations.",
    ]
    
    # Analyze single text
    print("\n" + "="*70)
    print("SINGLE TEXT ANALYSIS EXAMPLE")
    print("="*70)
    
    result = analyzer.analyze(examples[0])
    
    # Batch analysis
    print("\n" + "="*70)
    print("BATCH ANALYSIS EXAMPLE")
    print("="*70)
    
    batch_results = analyzer.batch_analyze(examples)
    
    # Custom text analysis
    print("\n" + "="*70)
    print("TRY YOUR OWN TEXT")
    print("="*70)
    print("\nYou can use the analyzer like this:")
    print("  analyzer = TextAnalyzer()")
    print("  result = analyzer.analyze('Your text here')")
    print()


if __name__ == "__main__":
    main()
