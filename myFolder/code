"""
CODE ANALYZER & RATING SYSTEM
Analyzes and rates Python code based on multiple criteria

Installation:
pip install radon pylint autopep8 bandit
"""

import ast
import re
import os
from typing import Dict, List, Tuple
from io import StringIO
import sys

# Code analysis tools
try:
    from radon.complexity import cc_visit
    from radon.metrics import mi_visit, h_visit
    from radon.raw import analyze
    RADON_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Install radon: pip install radon")
    RADON_AVAILABLE = False

try:
    import pylint.lint
    from pylint.reporters.text import TextReporter
    PYLINT_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Install pylint: pip install pylint")
    PYLINT_AVAILABLE = False

try:
    import bandit
    from bandit.core import manager as bandit_manager
    from bandit.core import config as bandit_config
    BANDIT_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Install bandit: pip install bandit")
    BANDIT_AVAILABLE = False


class CodeAnalyzer:
    """Comprehensive code analyzer and rating system"""
    
    def __init__(self):
        print("üîß Initializing Code Analyzer...")
        print("‚úÖ Code Analyzer ready!\n")
    
    def analyze(self, code: str) -> Dict:
        """
        Complete code analysis
        Returns dictionary with scores and analysis
        """
        print(f"\n{'='*70}")
        print("üíª ANALYZING CODE")
        print(f"{'='*70}\n")
        
        if not code.strip():
            return {'error': 'Empty code provided'}
        
        # Initialize results
        results = {
            'code': code,
            'line_count': len(code.split('\n')),
            'scores': {},
            'details': {},
            'final_score': 0.0,
            'rating': '',
            'issues': []
        }
        
        # Run all analysis
        print("1Ô∏è‚É£  Checking syntax...")
        syntax_score = self._check_syntax(code, results)
        
        print("2Ô∏è‚É£  Analyzing code quality...")
        quality_score = self._analyze_quality(code, results)
        
        print("3Ô∏è‚É£  Measuring complexity...")
        complexity_score = self._analyze_complexity(code, results)
        
        print("4Ô∏è‚É£  Checking maintainability...")
        maintainability_score = self._analyze_maintainability(code, results)
        
        print("5Ô∏è‚É£  Reviewing best practices...")
        practices_score = self._check_best_practices(code, results)
        
        print("6Ô∏è‚É£  Scanning for security issues...")
        security_score = self._check_security(code, results)
        
        print("7Ô∏è‚É£  Evaluating documentation...")
        documentation_score = self._check_documentation(code, results)
        
        # Calculate weighted final score
        weights = {
            'syntax': 0.20,
            'quality': 0.20,
            'complexity': 0.15,
            'maintainability': 0.15,
            'practices': 0.15,
            'security': 0.10,
            'documentation': 0.05
        }
        
        results['scores'] = {
            'syntax': syntax_score,
            'quality': quality_score,
            'complexity': complexity_score,
            'maintainability': maintainability_score,
            'practices': practices_score,
            'security': security_score,
            'documentation': documentation_score
        }
        
        final_score = sum(score * weights[name] for name, score in results['scores'].items())
        results['final_score'] = round(final_score, 2)
        results['rating'] = self._get_rating(final_score)
        
        # Display results
        self._display_results(results)
        
        return results
    
    def _check_syntax(self, code: str, results: Dict) -> float:
        """Check if code has valid syntax"""
        try:
            ast.parse(code)
            results['details']['syntax'] = "No syntax errors"
            return 100.0
        except SyntaxError as e:
            results['issues'].append(f"Syntax Error: {e.msg} at line {e.lineno}")
            results['details']['syntax'] = f"Syntax error at line {e.lineno}: {e.msg}"
            return 0.0
    
    def _analyze_quality(self, code: str, results: Dict) -> float:
        """Analyze code quality using basic metrics"""
        score = 100.0
        issues = []
        
        lines = code.split('\n')
        non_empty_lines = [l for l in lines if l.strip()]
        
        # Check line length
        long_lines = [i+1 for i, line in enumerate(lines) if len(line) > 100]
        if long_lines:
            score -= min(10, len(long_lines) * 2)
            issues.append(f"Long lines (>100 chars) at: {long_lines[:5]}")
        
        # Check for meaningful variable names
        short_vars = re.findall(r'\b([a-z])\s*=', code)
        if len(short_vars) > 3:
            score -= 10
            issues.append(f"Too many single-letter variables: {len(short_vars)}")
        
        # Check for comments
        comment_lines = [l for l in lines if l.strip().startswith('#')]
        comment_ratio = len(comment_lines) / max(len(non_empty_lines), 1)
        if comment_ratio < 0.05:
            score -= 10
            issues.append("Insufficient comments")
        
        # Check for proper spacing
        if '\t' in code:
            score -= 5
            issues.append("Uses tabs instead of spaces")
        
        # Check for multiple statements per line
        multi_statement_lines = [i+1 for i, l in enumerate(lines) if l.count(';') > 0]
        if multi_statement_lines:
            score -= min(10, len(multi_statement_lines) * 3)
            issues.append(f"Multiple statements per line at: {multi_statement_lines}")
        
        results['details']['quality'] = issues if issues else ["Good code quality"]
        return max(score, 0)
    
    def _analyze_complexity(self, code: str, results: Dict) -> float:
        """Analyze cyclomatic complexity"""
        if not RADON_AVAILABLE:
            return 70.0  # Default score
        
        try:
            complexity_blocks = cc_visit(code)
            if not complexity_blocks:
                results['details']['complexity'] = "Simple code structure"
                return 100.0
            
            complexities = [block.complexity for block in complexity_blocks]
            avg_complexity = sum(complexities) / len(complexities)
            max_complexity = max(complexities)
            
            # Score based on complexity
            if avg_complexity <= 5 and max_complexity <= 10:
                score = 100.0
                rating = "Excellent"
            elif avg_complexity <= 10 and max_complexity <= 20:
                score = 80.0
                rating = "Good"
            elif avg_complexity <= 15 and max_complexity <= 30:
                score = 60.0
                rating = "Moderate"
            else:
                score = 40.0
                rating = "Complex"
            
            results['details']['complexity'] = {
                'average': round(avg_complexity, 2),
                'maximum': max_complexity,
                'rating': rating,
                'blocks': len(complexity_blocks)
            }
            
            return score
        except:
            return 70.0
    
    def _analyze_maintainability(self, code: str, results: Dict) -> float:
        """Analyze maintainability index"""
        if not RADON_AVAILABLE:
            return 70.0
        
        try:
            mi = mi_visit(code, multi=True)
            
            # MI ranges: 0-9 (low), 10-19 (moderate), 20-100 (high)
            if mi >= 20:
                score = 100.0
                rating = "Highly Maintainable"
            elif mi >= 10:
                score = 70.0
                rating = "Moderately Maintainable"
            else:
                score = 40.0
                rating = "Hard to Maintain"
            
            results['details']['maintainability'] = {
                'index': round(mi, 2),
                'rating': rating
            }
            
            return score
        except:
            return 70.0
    
    def _check_best_practices(self, code: str, results: Dict) -> float:
        """Check Python best practices"""
        score = 100.0
        issues = []
        
        # Check for functions
        if 'def ' not in code:
            score -= 15
            issues.append("No functions defined (consider modular code)")
        
        # Check for classes (if code is substantial)
        if len(code.split('\n')) > 50 and 'class ' not in code:
            score -= 10
            issues.append("No classes for substantial code")
        
        # Check for main guard
        if 'if __name__' not in code and len(code.split('\n')) > 20:
            score -= 10
            issues.append("Missing if __name__ == '__main__' guard")
        
        # Check for docstrings
        docstring_pattern = r'"""[\s\S]*?"""|\'\'\'[\s\S]*?\'\'\''
        docstrings = re.findall(docstring_pattern, code)
        if 'def ' in code and not docstrings:
            score -= 15
            issues.append("Functions lack docstrings")
        
        # Check for error handling
        if 'def ' in code and 'try' not in code:
            score -= 10
            issues.append("No error handling (try-except)")
        
        # Check for hardcoded values
        magic_numbers = re.findall(r'(?<!\w)(\d{3,})(?!\w)', code)
        if len(magic_numbers) > 2:
            score -= 10
            issues.append(f"Magic numbers found: {magic_numbers[:3]}")
        
        # Check for global variables
        global_vars = re.findall(r'^[A-Z_]{2,}\s*=', code, re.MULTILINE)
        if len(global_vars) > 3:
            score -= 10
            issues.append(f"Too many global variables: {len(global_vars)}")
        
        results['details']['practices'] = issues if issues else ["Follows best practices"]
        return max(score, 0)
    
    def _check_security(self, code: str, results: Dict) -> float:
        """Check for basic security issues"""
        score = 100.0
        issues = []
        
        # Check for eval/exec usage
        if 'eval(' in code or 'exec(' in code:
            score -= 30
            issues.append("CRITICAL: Uses eval() or exec() - major security risk")
        
        # Check for hardcoded credentials
        credential_patterns = [
            r'password\s*=\s*["\'][^"\']+["\']',
            r'api_key\s*=\s*["\'][^"\']+["\']',
            r'secret\s*=\s*["\'][^"\']+["\']',
            r'token\s*=\s*["\'][^"\']+["\']'
        ]
        for pattern in credential_patterns:
            if re.search(pattern, code, re.IGNORECASE):
                score -= 25
                issues.append("CRITICAL: Hardcoded credentials detected")
                break
        
        # Check for SQL injection risks
        if 'execute(' in code and '+' in code and ('SELECT' in code or 'INSERT' in code):
            score -= 20
            issues.append("WARNING: Potential SQL injection risk")
        
        # Check for unsafe pickle
        if 'pickle.loads' in code:
            score -= 15
            issues.append("WARNING: Unsafe pickle.loads() usage")
        
        # Check for shell injection
        if 'os.system(' in code or 'subprocess.call(' in code:
            score -= 15
            issues.append("WARNING: Shell command execution detected")
        
        results['details']['security'] = issues if issues else ["No obvious security issues"]
        return max(score, 0)
    
    def _check_documentation(self, code: str, results: Dict) -> float:
        """Check documentation quality"""
        score = 100.0
        
        lines = code.split('\n')
        non_empty_lines = [l for l in lines if l.strip() and not l.strip().startswith('#')]
        
        # Check for module docstring
        if not code.strip().startswith('"""') and not code.strip().startswith("'''"):
            score -= 30
        
        # Check for comments
        comment_lines = [l for l in lines if l.strip().startswith('#')]
        if len(non_empty_lines) > 0:
            comment_ratio = len(comment_lines) / len(non_empty_lines)
            if comment_ratio < 0.05:
                score -= 30
            elif comment_ratio < 0.10:
                score -= 20
        
        # Check for function docstrings
        docstring_pattern = r'"""[\s\S]*?"""|\'\'\'[\s\S]*?\'\'\''
        docstrings = len(re.findall(docstring_pattern, code))
        functions = len(re.findall(r'def \w+', code))
        
        if functions > 0:
            if docstrings == 0:
                score -= 20
            elif docstrings < functions * 0.5:
                score -= 10
        
        results['details']['documentation'] = {
            'comment_lines': len(comment_lines),
            'docstrings': docstrings,
            'functions': functions
        }
        
        return max(score, 0)
    
    def _get_rating(self, score: float) -> str:
        """Convert score to rating"""
        if score >= 90:
            return "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent"
        elif score >= 80:
            return "‚≠ê‚≠ê‚≠ê‚≠ê Very Good"
        elif score >= 70:
            return "‚≠ê‚≠ê‚≠ê Good"
        elif score >= 60:
            return "‚≠ê‚≠ê Fair"
        elif score >= 50:
            return "‚≠ê Poor"
        else:
            return "‚ùå Needs Major Improvement"
    
    def _display_results(self, results: Dict):
        """Display analysis results"""
        print(f"\n{'='*70}")
        print("üìä CODE ANALYSIS RESULTS")
        print(f"{'='*70}\n")
        
        print(f"üìÑ Code Statistics:")
        print(f"   Lines of Code: {results['line_count']}")
        
        print(f"\nüéØ SCORES BY CATEGORY:")
        for category, score in results['scores'].items():
            print(f"   {category.capitalize():<20} {score:>6.2f}/100")
        
        print(f"\n{'‚îÄ'*70}")
        print(f"üèÜ FINAL SCORE: {results['final_score']:.2f}/100")
        print(f"üìà RATING: {results['rating']}")
        print(f"{'‚îÄ'*70}\n")
        
        # Show issues
        if results['issues']:
            print("‚ö†Ô∏è  CRITICAL ISSUES:")
            for issue in results['issues']:
                print(f"   ‚Ä¢ {issue}")
            print()
        
        # Show details
        print("üìã DETAILED ANALYSIS:")
        for category, details in results['details'].items():
            print(f"\n   {category.upper()}:")
            if isinstance(details, dict):
                for key, value in details.items():
                    print(f"      {key}: {value}")
            elif isinstance(details, list):
                for item in details[:5]:  # Show first 5
                    print(f"      ‚Ä¢ {item}")
            else:
                print(f"      {details}")
        
        print(f"\n{'='*70}\n")


# ============================================================================
# USAGE EXAMPLE
# ============================================================================

def main():
    """Example usage"""
    
    print("\n" + "üéØ"*35)
    print("     CODE ANALYZER & RATING SYSTEM")
    print("üéØ"*35 + "\n")
    
    analyzer = CodeAnalyzer()
    
    # ========================================================================
    # üëâ PASTE YOUR CODE HERE TO ANALYZE üëà
    # ========================================================================
    
    code_to_analyze = """
def calculate_average(numbers):
    total = sum(numbers)
    count = len(numbers)
    return total / count

result = calculate_average([1, 2, 3, 4, 5])
print(result)
"""
    
    # Analyze the code
    results = analyzer.analyze(code_to_analyze)
    
    # ========================================================================
    # Example with better code
    # ========================================================================
    
    print("\n\n" + "="*70)
    print("ANALYZING BETTER CODE EXAMPLE")
    print("="*70)
    
    better_code = """
\"\"\"
Module for statistical calculations.
Provides functions for common statistical operations.
\"\"\"

def calculate_average(numbers):
    \"\"\"
    Calculate the average of a list of numbers.
    
    Args:
        numbers (list): List of numeric values
        
    Returns:
        float: The average value
        
    Raises:
        ValueError: If the list is empty
    \"\"\"
    if not numbers:
        raise ValueError("Cannot calculate average of empty list")
    
    total = sum(numbers)
    count = len(numbers)
    return total / count


def calculate_median(numbers):
    \"\"\"Calculate the median of a list of numbers.\"\"\"
    if not numbers:
        raise ValueError("Cannot calculate median of empty list")
    
    sorted_numbers = sorted(numbers)
    n = len(sorted_numbers)
    
    if n % 2 == 0:
        # Even number of elements
        middle1 = sorted_numbers[n // 2 - 1]
        middle2 = sorted_numbers[n // 2]
        return (middle1 + middle2) / 2
    else:
        # Odd number of elements
        return sorted_numbers[n // 2]


if __name__ == "__main__":
    # Test the functions
    try:
        test_data = [1, 2, 3, 4, 5]
        avg = calculate_average(test_data)
        med = calculate_median(test_data)
        
        print(f"Average: {avg}")
        print(f"Median: {med}")
    except ValueError as e:
        print(f"Error: {e}")
"""
    
    results2 = analyzer.analyze(better_code)


if __name__ == "__main__":
    main()
